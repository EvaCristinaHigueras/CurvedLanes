import cv2
import numpy as np
import cv2.ximgproc as ximgproc

# Adjustable Parameters
WIDENESS = 10  # Thickness of lane lines and centerline
ROI_SIZE_RATIO = 0.5  # Square ROI size (percentage of screen width)
SMOOTHING_DEGREE = 3  # Polynomial degree for smoothing centerline
INTERPOLATION_POINTS = 50  # Ensures equal spacing between contour points
END_SMOOTHING_WINDOW = 5  # Moving average smoothing window for ends

def initialize_video_writer(cap, filename="output.avi"):
    """ Initializes the video writer to record the output.
        Gets the video dimensions for the camera. 
        Sets the output file format and frame rate. 
        Returns a VideoWriter object for saving frames."""
    frame_width = int(cap.get(3)) 
    frame_height = int(cap.get(4))  
    fourcc = cv2.VideoWriter_fourcc(*'XVID')  
    fps = 20 

    return cv2.VideoWriter(filename, fourcc, fps, (frame_width, frame_height))

def midCalc(contours):
    """ Calculates the midline by averaging corresponding points from both contours. 
        If fewer than 2 contours are detected, none is returned.
        If there are at least 2 contours, it first elimantes the single dimensional entries into the array.
        Then ensures the contours have the same number of points.
        Lastly calculates the midpoint, and returns the midline (which is a line comprised of each midpoint)."""

    if len(contours) < 2:
        return None

    left_contour = contours[0].squeeze()
    right_contour = contours[1].squeeze()

    min_length = min(len(left_contour), len(right_contour))
    left_contour = left_contour[:min_length]
    right_contour = right_contour[:min_length]

    mid_x = (left_contour[:, 0] + right_contour[:, 0]) // 2
    mid_y = (left_contour[:, 1] + right_contour[:, 1]) // 2
    midline = np.column_stack((mid_x, mid_y))

    return midline

def contourDetection(frame):
    """ Detects lane contours and calculates the midline.
        First a square Region of Interest (ROI) is extracted in the center of the frame (previously decided to be 50% of the screen).
        Then converts the frames to grayscale, blurs using GaussianBlur, and uses Canny edge detection and skeletonization to extract lane edges.
        The two largest lane contours are selected out of all of the contours found, and are drawn in green while centerline is drawn in red.
        This processed frame is returned.
        """
    height, width, _ = frame.shape

    
    roi_size = int(width * ROI_SIZE_RATIO)
    roi_x1 = (width // 2) - (roi_size // 2)
    roi_y1 = (height // 2) - (roi_size // 2)
    roi_x2 = roi_x1 + roi_size
    roi_y2 = roi_y1 + roi_size

    roi = frame[roi_y1:roi_y2, roi_x1:roi_x2]  # Extract ROI (square region)

    
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)

   
    skeleton = ximgproc.thinning(edges)

   
    contours, _ = cv2.findContours(skeleton, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

  
    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:2]

 
    if len(contours) < 2:
        return frame

   
    for contour in contours:
        contour[:, :, 0] += roi_x1
        contour[:, :, 1] += roi_y1

  
    mask = np.zeros_like(frame, dtype=np.uint8)

   
    for contour in contours:
        cv2.drawContours(mask, [contour], -1, (0, 255, 0), WIDENESS)


    midline = midCalc(contours)
    if midline is not None and len(midline) > 1:
        for i in range(len(midline) - 1):
            cv2.line(mask, tuple(midline[i]), tuple(midline[i + 1]), (0, 0, 255), WIDENESS)

   
    blended_frame = cv2.addWeighted(frame, 1, mask, 0.7, 0)

  
    cv2.rectangle(blended_frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (255, 255, 255), 2)

    return blended_frame

def main():
    """ Main function to run lane detection in real-time and record video. 
        First, initialize the camera (for stream) and videowriter (for saved video).
        Then read each frame while the camera receives frames.
        Apply lane detection and midline calculation on each frame.
        Display the processed frames live, and save them to a processed video to output as a file.
        Stop the program once 'q' is pressed."""

    cap = cv2.VideoCapture(0)  
    out = initialize_video_writer(cap)  

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        processed_frame = contourDetection(frame)
        cv2.imshow("Lane Detection with Centerline", processed_frame)

        # Write the processed frame to the video file
        out.write(processed_frame)

        if cv2.waitKey(1) & 0xFF == ord('q'): 
            break

    cap.release()
    out.release()  
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
